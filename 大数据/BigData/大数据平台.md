#大数据管理平台
##

###概述

现在的想法是将所有的大数据方面的技术集成到一起，建立一个集 集群管理，数据存储，数据分析处理，数据可视化功能合为一体的大数据平台

如何做：数据存储直接使用HDFS、HIVE等存储技术；数据分析处理可以集成现有的各种数据处理框架，将其中的一些函数用API的方式提供给用户；数据可视化与上述相同

###架构

1.数据集成

kafka flume sqoop

2.数据存储

HDFS Hbase Hive

3.数据计算

内存计算 spark
流式计算 spark storming
离线计算 MapReduce Hive

###框架介绍

1.hadoop

不用说 数据分布式存储和数据分布式处理

2.spark

内存计算 流计算等各种计算

3.Hbase

数据库

4.Hive

数据仓库

5.flume

一个实时数据采集系统，可以接管文件系统当中的一个文件夹或者文件，当接管的东西发生改变时就会进行采集，并将新的东西输入到另一个地方

agent分布在单个结点上每个结点就是一个agent（source收集 channel处理 sink发送）

6.kafka

与flume相同，也是一个实时数据采集系统

但是flume和kafka也有不同点，就是kafka的高可用和flume对于hadoop生态的接口

kafka是一个生产者-消费者模式的系统

kafka也可以在一定时间内持久化数据，同时也会有副本，所以可用性很高

常用的就是将两个东西整合在一起

	1.flume从各个地方接收数据，直接sink到kafka当中，kafka再将数据分发给下面的多个消费者
	
	2.flume接收数据，sink到kafka中，flume作为kafka的消费者消费数据，sink到hbase hive等组件当中

7.sqoop

也是一个数据传输工具，可以将数据库当中的数据导入hive hbase hdfs当中，可以用来做离线数据接入

###关于框架方面的思考

首先，大数据平台可以分成两个部分

1.流数据处理模块

2.离线数据处理模块

流数据处理，就是通过对日志信息进行实时获取，传递到sparkstreaming当中进行处理

离线数据处理，通过sqoop来定时导入到hive或者hbase中，再通过他们来对这些数据进行计算

其实，整个大数据平台的搭建，并不是想象当中那样的是一个整体，而是各个组件其实是相互独立的，只是通过数据，将各个组件链接在了一起。