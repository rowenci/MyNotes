# R-CNN

## 计算机视觉的各种应用

![image-20210825164311604](F:\MyNotes\人工智能\论文笔记\R-CNN\image-20210825164311604.png)

![image-20210825164417646](F:\MyNotes\人工智能\论文笔记\R-CNN\image-20210825164417646.png)

![image-20210825164431276](F:\MyNotes\人工智能\论文笔记\R-CNN\image-20210825164431276.png)

![image-20210825164525359](F:\MyNotes\人工智能\论文笔记\R-CNN\image-20210825164525359.png)

## 目标检测派系分类

双阶段目标检测模型：首先生成候选框，然后对候选框进行逐一甄别（分类）。

单阶段目标检测模型：不需要生成候选框，直接把图像喂到模型当中，直接生成目标检测的结果

## selective search

![image-20210825171334468](F:\MyNotes\人工智能\论文笔记\R-CNN\image-20210825171334468.png)

首先，在输入图片当中找到颜色、纹理、大小、形状一致的区域，对这些区域进行加权合并，最终生成大概2k的候选框。然后一步步地对相似候选框进行合并，最后就行获得好的候选框。

![image-20210825171602189](F:\MyNotes\人工智能\论文笔记\R-CNN\image-20210825171602189.png)

## R-CNN原理

R : Region

首先，使用selective search方法，在输入的图像当中生成多个候选框（~2k）。这些候选框可能是最终的目标，也可能不是。

然后，将每个候选框，不管它的长宽、比例、大小，直接统一强制resize成227 * 227的image region。并将这些候选框，逐一喂到卷积神经网络当中。（原论文是AlexNet，所以要将候选框编程227 * 227）。通过卷积神经网络来提取4096维的全连接层输出的特征。（这一部分可以参考AlexNet每一层的输出来进行理解）

至于为什么强行将候选框resize成227 * 227。因为有全连接层。

最后，对每个输出的特征，使用SVM来对它进行分类。针对每个数据集中物体类别的不同，使用不同的SVM来对其进行分类。如果有20个类别，就使用20个SVM。

同时，对这个特征使用BoundingBox Regression，来对候选框进行精修。

最终生成了每个候选框的类别与候选框精修过后的位置。

![image-20210825170037597](F:\MyNotes\人工智能\论文笔记\R-CNN\image-20210825170037597.png)

这一整个系统中的每一个步骤都不能出问题。如果某一个步骤优化不到位，都会对结果产生很大的影响。所以这并不是一个端到端的系统，严重依赖于上下游处理模块的协作。



有个问题：为什么不直接用softmax分类，而要用SVM呢？

1.Fine Tune时，和训练各类别的SVM时。它的正负样本选择的策略是不同的。所以如果使用softmax。就都得按fine tuning的策略来。但是如果使用SVM的策略会更好。

2.不想。



BoundingBox Regression也很重要



![image-20210825170747979](F:\MyNotes\人工智能\论文笔记\R-CNN\image-20210825170747979.png)

从这个图可以看到，这个R-CNN是很耗时的。

## 改进R-CNN

针对R-CNN，可以做出以下改进

1. 提取候选框：EdgeBoxes、RPN网络
2. 共享卷积运算：SPPNet、Fast R-CNN
3. 兼容任意尺寸图像：SPP、ROI Pooling
4. 预设长宽比：Anchor
5. 网络结构：duandaod
6. 融合各层特征：FPN

## 总结

R-CNN算法流程可以分成4个步骤

1. 针对一张图像，生成约2k个候选框（selective search）
2. 针对每个候选框，使用CNN来提取特征
3. 将特征送入每一类的SVM，判断是否属于该类别
4. 使用BoundingBox Regression精修候选框的位置

